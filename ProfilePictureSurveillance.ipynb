{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befdc38a-b1c3-4b26-91a2-a85aa3c3c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import functools\n",
    "from typing import List, Optional, Union, Tuple, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from transformers import Pipeline, pipeline\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from timm.data import resolve_data_config, create_transform\n",
    "\n",
    "# ── Configuration ──────────────────────────────────────────────────────────────\n",
    "INPUT_CSV            = \"images_nsfw.csv\"\n",
    "OUTPUT_CSV           = \"images_nsfw_2.csv\"\n",
    "URL_COLUMN           = \"PROFILE_IMAGE\"\n",
    "BATCH_SIZE           = 16\n",
    "DOWNLOAD_TIMEOUT     = 5\n",
    "MAX_RETRIES          = 3\n",
    "NSFW_THRESHOLD_1     = 0.5   # threshold for Falconsai\n",
    "NSFW_THRESHOLD_2     = 0.3   # threshold for Marqo\n",
    "ENSEMBLE_THRESHOLD   = 0.5   # threshold on average score\n",
    "LOG_FILE             = \"nsfw_detect.log\"\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "        logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def get_device() -> Union[int, str]:\n",
    "    if torch.cuda.is_available():\n",
    "        logging.info(\"Using CUDA device\")\n",
    "        return 0\n",
    "    if torch.backends.mps.is_available():\n",
    "        logging.info(\"Using MPS device\")\n",
    "        return \"mps\"\n",
    "    logging.info(\"Using CPU\")\n",
    "    return -1\n",
    "\n",
    "\n",
    "def make_session(timeout: float, max_retries: int) -> requests.Session:\n",
    "    sess = requests.Session()\n",
    "    retries = Retry(\n",
    "        total=max_retries,\n",
    "        backoff_factor=0.3,\n",
    "        status_forcelist=[500,502,503,504],\n",
    "        allowed_methods=[\"GET\"]\n",
    "    )\n",
    "    sess.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "    sess.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "    sess.request = functools.partial(sess.request, timeout=timeout)  # type: ignore\n",
    "    return sess\n",
    "\n",
    "\n",
    "def download_image(session: requests.Session, url: str) -> Optional[Image.Image]:\n",
    "    try:\n",
    "        r = session.get(url)\n",
    "        r.raise_for_status()\n",
    "        return Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Could not load {url!r}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def read_input_csv(path: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(path, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        logging.warning(f\"UTF-8 decode failed for {path}, retry with latin1\")\n",
    "        return pd.read_csv(path, encoding='latin1')\n",
    "\n",
    "\n",
    "def extract_nsfw_score(out: List[List[dict]]) -> List[Optional[float]]:\n",
    "    scores: List[Optional[float]] = []\n",
    "    for item in out:\n",
    "        nsfw = next((x for x in item if x[\"label\"].lower() == \"nsfw\"), None)\n",
    "        scores.append(nsfw[\"score\"] if nsfw else None)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def run_nsfw_detection(\n",
    "    df: pd.DataFrame,\n",
    "    url_col: str = URL_COLUMN,\n",
    "    batch_size: int = BATCH_SIZE\n",
    ") -> pd.DataFrame:\n",
    "    device = get_device()\n",
    "\n",
    "    # Load first model via Hugging Face pipeline\n",
    "    m1: Pipeline = pipeline(\n",
    "        \"image-classification\",\n",
    "        model=\"Falconsai/nsfw_image_detection\",\n",
    "        device=device\n",
    "    )\n",
    "    # Load second model (Marqo) via timm\n",
    "    m2_model = timm.create_model(\"hf_hub:Marqo/nsfw-image-detection-384\", pretrained=True)\n",
    "    # extract config dict for labels\n",
    "    config_dict: Optional[Dict[str, Any]] = None\n",
    "    if hasattr(m2_model, \"pretrained_cfg\") and isinstance(m2_model.pretrained_cfg, dict):\n",
    "        config_dict = m2_model.pretrained_cfg  # type: ignore\n",
    "    elif hasattr(m2_model, \"default_cfg\") and isinstance(m2_model.default_cfg, dict):\n",
    "        config_dict = m2_model.default_cfg  # type: ignore\n",
    "    else:\n",
    "        raise AttributeError(\"Cannot find a config dict on Marqo model for labels\")\n",
    "    labels2 = config_dict.get(\"label_names\") or config_dict.get(\"labels\")\n",
    "    if labels2 is None or not isinstance(labels2, list):\n",
    "        raise AttributeError(\"No 'label_names' or 'labels' list found in Marqo model config dict\")\n",
    "    # nsfw_idx = labels2.index(\"nsfw\")\n",
    "\n",
    "    # determine NSFW index robustly\n",
    "    labels2_lower = [l.lower() for l in labels2]\n",
    "    if \"nsfw\" in labels2_lower:\n",
    "        nsfw_idx = labels2_lower.index(\"nsfw\")\n",
    "    elif \"unsafe\" in labels2_lower:\n",
    "        nsfw_idx = labels2_lower.index(\"unsafe\")\n",
    "    else:\n",
    "        # fallback to second class in binary scenario\n",
    "        nsfw_idx = 1  # assume index 1 corresponds to NSFW\n",
    "        logging.warning(f\"'nsfw' not found in labels {labels2}, defaulting nsfw_idx=1\")\n",
    "        \n",
    "    m2_model.eval()\n",
    "    m2_device = next(m2_model.parameters()).device\n",
    "    # m2_config = resolve_data_config(m2_model)\n",
    "    m2_config = resolve_data_config({}, model=m2_model)\n",
    "\n",
    "    m2_transforms = create_transform(**m2_config, is_training=False)\n",
    "\n",
    "    session = make_session(DOWNLOAD_TIMEOUT, MAX_RETRIES)\n",
    "    total = len(df)\n",
    "    processed_urls = set()\n",
    "    if os.path.exists(OUTPUT_CSV):\n",
    "        processed_urls = set(read_input_csv(OUTPUT_CSV)[url_col].astype(str))\n",
    "        logging.info(f\"Resuming: {len(processed_urls)} URLs already done\")\n",
    "\n",
    "    results: List[dict] = []\n",
    "    pbar = tqdm(total=total, desc=\"Images\", unit=\"img\", file=sys.stdout)\n",
    "\n",
    "    for start in range(0, total, batch_size):\n",
    "        batch = df.iloc[start:start+batch_size]\n",
    "        urls = batch[url_col].astype(str).tolist()\n",
    "\n",
    "        # Download images\n",
    "        images = [download_image(session, u) if u not in processed_urls else None for u in urls]\n",
    "\n",
    "        # Prepare classification for new\n",
    "        idxs = [i for i,u in enumerate(urls) if images[i] is not None]\n",
    "        to_classify = [images[i] for i in idxs]\n",
    "\n",
    "        # Model1 scores\n",
    "        scores1 = [None]*len(urls)\n",
    "        if to_classify:\n",
    "            raw1 = m1(to_classify, top_k=None)  # type: ignore\n",
    "            out1 = extract_nsfw_score(raw1)\n",
    "            for pos, s in zip(idxs, out1):\n",
    "                scores1[pos] = s\n",
    "\n",
    "        # Model2 scores\n",
    "        scores2 = [None]*len(urls)\n",
    "        if to_classify:\n",
    "            batch_t = torch.stack([m2_transforms(img) for img in to_classify]).to(m2_device)\n",
    "            with torch.no_grad(): logits = m2_model(batch_t).softmax(dim=-1).cpu()\n",
    "            out2 = [float(logits[j, nsfw_idx]) for j in range(logits.shape[0])]\n",
    "            for pos, s in zip(idxs, out2):\n",
    "                scores2[pos] = s\n",
    "\n",
    "        # Ensemble + rotation re-check\n",
    "        final_scores = [None]*len(urls)\n",
    "        final_flags  = [False]*len(urls)\n",
    "        for i in idxs:\n",
    "            s1 = scores1[i] or 0.0\n",
    "            s2 = scores2[i] or 0.0\n",
    "            # if flagged by either, re-check rotations\n",
    "            if s1 >= NSFW_THRESHOLD_1 or s2 >= NSFW_THRESHOLD_2:\n",
    "                rots = [images[i].rotate(90, expand=True), images[i].rotate(-90, expand=True)]\n",
    "                r1 = extract_nsfw_score(m1(rots, top_k=None))  # type: ignore\n",
    "                batch_r2 = torch.stack([m2_transforms(r) for r in rots]).to(m2_device)\n",
    "                with torch.no_grad(): r_logits = m2_model(batch_r2).softmax(dim=-1).cpu()\n",
    "                r2 = [float(r_logits[j, nsfw_idx]) for j in range(r_logits.shape[0])]\n",
    "                min1 = min([s1] + [x or s1 for x in r1])\n",
    "                min2 = min([s2] + r2)\n",
    "            else:\n",
    "                min1, min2 = s1, s2\n",
    "            avg = (min1 + min2) / 2\n",
    "            final_scores[i] = avg\n",
    "            final_flags[i]  = avg >= ENSEMBLE_THRESHOLD\n",
    "\n",
    "        # Append results & checkpoint\n",
    "        for u,s1,s2,avg,flag in zip(urls, scores1, scores2, final_scores, final_flags):\n",
    "            if u not in processed_urls:\n",
    "                results.append({url_col: u,\n",
    "                                \"score1\": s1,\n",
    "                                \"score2\": s2,\n",
    "                                \"score_final\": avg,\n",
    "                                \"nsfw_flag\": flag})\n",
    "                processed_urls.add(u)\n",
    "        # checkpoint\n",
    "        pd.DataFrame(results).to_csv(OUTPUT_CSV, index=False, encoding='utf-8')\n",
    "\n",
    "        pbar.update(len(urls))\n",
    "        pbar.set_postfix({\"scanned\": len(processed_urls),\n",
    "                          \"nsfw_found\": sum(r[\"nsfw_flag\"] for r in results)})\n",
    "    pbar.close()\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_in = read_input_csv(INPUT_CSV)\n",
    "    # 1) Filter to only NSFW rows\n",
    "    df_in = df_in[df_in[\"nsfw_flag\"] == True].copy()\n",
    "    \n",
    "    # 2) Drop the last three columns by position\n",
    "    df_in = df_in.iloc[:, :-3]\n",
    "    \n",
    "    # (optional) reset the index if you like\n",
    "    df_in.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    if URL_COLUMN not in df_in:\n",
    "        raise RuntimeError(f\"Input must contain '{URL_COLUMN}' column\")\n",
    "    logging.info(\"Starting NSFW ensemble detection…\")\n",
    "    df_out = run_nsfw_detection(df_in)\n",
    "    df_out.to_csv(OUTPUT_CSV, index=False, encoding='utf-8')\n",
    "    logging.info(f\"Done. Results at {OUTPUT_CSV}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
